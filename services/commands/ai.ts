import { GenerativeModel } from '@google/generative-ai';
import { GuildMember, NewsChannel, TextChannel } from 'discord.js';
import { Chat as ChatModel } from '../../models/chat.js';
import '../../utils/logger.js';

import { ChatHistory, ChatMessage, ExecuteParams, Command } from './types.js';

const FALLBACK_MODELS = [
    'gemini-2.0-flash-lite-preview',
    'gemini-2.0-flash-lite',
    'gemini-2.0-flash-lite-001',
    'gemini-flash-lite-latest',
    'gemini-2.0-flash',
    'gemini-2.0-flash-001',
    'gemini-2.0-flash-exp',
    'gemini-flash-latest',
    'gemini-pro-latest'
];
interface AiCommand extends Command {
    summarizeAndUpdateChatTitle: (userId: string, model: GenerativeModel) => Promise<void>;
    generateChatTitle: (userId: string, model: GenerativeModel) => Promise<string>;
}

export default {
    name: 'ai',
    description: 'Talk to the AI with persistent conversation history using the current chat. ü§ñ',
    
    async execute({ message, args, config, logModAction, sendEmbedMessage, client, model, chatM, createModel }: ExecuteParams): Promise<void> {
        if (!args.length) {
            message.reply('‚ö†Ô∏è B·∫°n c·∫ßn nh·∫≠p n·ªôi dung ƒë·ªÉ g·ªçi AI.');
            return;
        }

        let userId: string = message.author.id;
        const member: GuildMember | undefined = message.mentions.members?.first();
        if (member) {
            userId = member.id;
            args.shift();
        }
        const prompt: string = args.join(' ');

        try {
            let processingMsg;
            if (message.channel instanceof TextChannel || message.channel instanceof NewsChannel) {
                processingMsg = await message.channel.send('ü§î ƒêang x·ª≠ l√Ω...');
            }
            
            let historyRows = await chatM.getUserChatHistory(userId, 5);
            
            let conversation: ChatHistory[] = historyRows.map(row => ({
                role: row.role,
                parts: [{ text: row.content }]
            }));
            
            console.log(`üó£Ô∏è L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán c·ªßa ${userId}: ${JSON.stringify(conversation)}`);
            
            const models = [model, ...FALLBACK_MODELS.map(m => createModel(m))];
            let success = false;
            let usedModel = model;

            for (let i = 0; i < models.length; i++) {
                const currentModel = models[i];
                try {
                    if (conversation.length === 0) {
                        const result = await currentModel.generateContent(prompt);
                        const content = result.response.text();
                        await chatM.addChatMessage(userId, 'user', prompt);
                        await chatM.addChatMessage(userId, 'model', content);
                        this.summarizeAndUpdateChatTitle(userId, currentModel).catch(e => console.error("L·ªói t√≥m t·∫Øt ng·∫ßm:", e));
                        await processingMsg?.delete();
                        await sendEmbedMessage(message.channel, message.author, content);
                        success = true;
                        usedModel = currentModel;
                        break;
                    } 
                    
                    try {
                        const chat = currentModel.startChat({
                            history: conversation,
                            generationConfig: { maxOutputTokens: 1000 }
                        });
                        const result = await chat.sendMessage(prompt);
                        const content = result.response.text();
                        await chatM.addChatMessage(userId, 'user', prompt);
                        await chatM.addChatMessage(userId, 'model', content);
                        this.summarizeAndUpdateChatTitle(userId, currentModel).catch(e => console.error("L·ªói t√≥m t·∫Øt ng·∫ßm:", e));
                        await processingMsg?.delete();
                        await sendEmbedMessage(message.channel, message.author, content);
                        success = true;
                        usedModel = currentModel;
                        break;
                    } catch (chatError: any) {
                         // Check if this inner error is quota
                         if (chatError.message?.includes('429') || chatError.status === 429) {
                             throw chatError; // Rethrow to outer fallback loop
                         }
                         
                         // Not quota, try new chat fallback logic with CURRENT model
                        console.error(`L·ªói khi g·ªçi startChat: ${chatError.message}`);
                        await processingMsg?.delete();
                        message.reply('üîÑ ƒêang th·ª≠ l·∫°i v·ªõi cu·ªôc tr√≤ chuy·ªán m·ªõi...');
                        
                        await chatM.createNewChat(userId);
                        const result = await currentModel.generateContent(prompt); 
                        const content = result.response.text();
                        
                        await chatM.addChatMessage(userId, 'user', prompt);
                        await chatM.addChatMessage(userId, 'model', content);
                        this.summarizeAndUpdateChatTitle(userId, currentModel).catch(e => console.error("L·ªói t√≥m t·∫Øt ng·∫ßm:", e));
                        await sendEmbedMessage(message.channel, message.author, content);
                        success = true; // Fallback succeeded
                        usedModel = currentModel;
                        break;
                    }
                } catch (error: any) {
                     const isQuota = error.message?.includes('429') || error.status === 429;
                     if (isQuota && i < models.length - 1) {
                         console.log(`‚ö†Ô∏è Model limit reached, switching to backup model... (${i + 1}/${models.length})`);
                         continue;
                     }
                     
                     if (i === models.length - 1) {
                         console.error(`‚ùå L·ªói cu·ªëi c√πng khi g·ªçi AI: ${error.message}`);
                         await processingMsg?.delete();
                         if (isQuota) {
                            message.reply('‚ùå T·∫•t c·∫£ c√°c model ƒë·ªÅu ƒëang b·∫≠n ho·∫∑c h·∫øt h·∫°n m·ª©c. Vui l√≤ng th·ª≠ l·∫°i sau.');
                         } else {
                            message.reply('‚ùå C√≥ l·ªói x·∫£y ra khi g·ªçi AI.');
                         }
                     }
                }
            }
        } catch (error: any) {
            console.error(`‚ùå L·ªói chung khi g·ªçi AI: ${error.message}`);
            message.reply('‚ùå C√≥ l·ªói x·∫£y ra khi g·ªçi AI. Vui l√≤ng th·ª≠ l·∫°i sau.');
        }
    },

    async summarizeAndUpdateChatTitle(userId: string, model: GenerativeModel): Promise<void> {
        try {
            const currentChat = await (new ChatModel()).getCurrentChat(userId);
    
            if (currentChat.title && !currentChat.title.startsWith(`[${currentChat.chat_id}] Cu·ªôc tr√≤ chuy·ªán`)) {
                // If title already exists and is not just the default, skip
                return;
            }

            const messages: ChatMessage[] = await (new ChatModel()).getChatMessages(currentChat.id, 5);
    
            if (messages.length === 0) {
                return;
            }
    
            let context: string = messages.map(msg => 
                `${msg.role === 'user' ? 'Ng∆∞·ªùi d√πng' : 'AI'}: ${msg.content}`
            ).reverse().join('\n');
    
            const prompt: string = `D·ª±a v√†o ƒëo·∫°n h·ªôi tho·∫°i sau, h√£y t·∫°o m·ªôt ti√™u ƒë·ªÅ ng·∫Øn g·ªçn (d∆∞·ªõi 50 k√Ω t·ª±) cho cu·ªôc tr√≤ chuy·ªán n√†y:\n\n${context}\n\nTi√™u ƒë·ªÅ:`;
    
            const result = await model.generateContent({
                contents: [{ role: 'user', parts: [{ text: prompt }] }],
                generationConfig: { maxOutputTokens: 100 }
            });
            let title: string = result.response.text().trim();
    
            if (title.length > 50) {
                title = title.substring(0, 47) + '...';
            }
    
            title = `[${currentChat.chat_id}] ${title}`;
    
            await (new ChatModel()).save({ title }, { id: currentChat.id });
    
            console.log(`‚úÖ ƒê√£ c·∫≠p nh·∫≠t ti√™u ƒë·ªÅ cho cu·ªôc tr√≤ chuy·ªán ${currentChat.id}: ${title}`);
    
        } catch (error: any) {
            console.error(`‚ùå L·ªói khi t√≥m t·∫Øt cu·ªôc tr√≤ chuy·ªán: ${error.message}`);
        }
    }
} as AiCommand;